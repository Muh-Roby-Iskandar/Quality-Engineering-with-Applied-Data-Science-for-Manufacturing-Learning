{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Robyi\\Documents\\Data Science Dataset\\elecproduction.csv\")\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(10, 4), title=\"Electricity Production Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, lags=12):\n",
    "    data = df.copy()\n",
    "    for lag in range(1, lags + 1):\n",
    "        data[f\"lag_{lag}\"] = df[\"IPG2211A2N\"].shift(lag)\n",
    "    return data.dropna()\n",
    "\n",
    "df = create_features(df, lags=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_scaled[:, 1:], train_scaled[:, 0]\n",
    "X_test, y_test = test_scaled[:, 1:], test_scaled[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "def create_bnn(hidden_units=16, learning_rate=0.01):\n",
    "    model = tf.keras.Sequential([\n",
    "        tfp.layers.DenseVariational(\n",
    "            units=hidden_units,\n",
    "            make_prior_fn=lambda: tfd.Normal(loc=0., scale=1.),\n",
    "            make_posterior_fn=lambda: tfd.Normal(\n",
    "                loc=tf.Variable(tf.random.normal([hidden_units])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random.normal([hidden_units])))\n",
    "            ),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        tfp.layers.DenseVariational(\n",
    "            units=hidden_units,\n",
    "            make_prior_fn=lambda: tfd.Normal(loc=0., scale=1.),\n",
    "            make_posterior_fn=lambda: tfd.Normal(\n",
    "                loc=tf.Variable(tf.random.normal([hidden_units])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random.normal([hidden_units])))\n",
    "            ),\n",
    "            activation=\"relu\"\n",
    "        ),\n",
    "        tfp.layers.DenseVariational(\n",
    "            units=1,\n",
    "            make_prior_fn=lambda: tfd.Normal(loc=0., scale=1.),\n",
    "            make_posterior_fn=lambda: tfd.Normal(\n",
    "                loc=tf.Variable(tf.random.normal([1])),\n",
    "                scale=tf.nn.softplus(tf.Variable(tf.random.normal([1])))\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss=\"mse\",\n",
    "                  metrics=[\"mae\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_units = trial.suggest_int(\"hidden_units\", 8, 64)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = create_bnn(hidden_units, learning_rate)\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=50, verbose=0, batch_size=16, validation_split=0.2)\n",
    "    \n",
    "    val_loss = history.history[\"val_loss\"][-1]\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = create_bnn(hidden_units=best_params[\"hidden_units\"], learning_rate=best_params[\"learning_rate\"])\n",
    "\n",
    "history = best_model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_samples = np.array([best_model(X_test) for _ in range(100)])\n",
    "\n",
    "y_pred_mean = y_pred_samples.mean(axis=0).flatten()\n",
    "y_pred_std = y_pred_samples.std(axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred_mean)\n",
    "r2 = r2_score(y_test, y_pred_mean)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"R-squared (RÂ²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_actual = scaler.inverse_transform(np.column_stack([y_test, X_test]))[:, 0]\n",
    "y_pred_actual = scaler.inverse_transform(np.column_stack([y_pred_mean, X_test]))[:, 0]\n",
    "y_pred_std_actual = scaler.inverse_transform(np.column_stack([y_pred_std, X_test]))[:, 0]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index[train_size:], y_test_actual, label=\"Actual\", color=\"red\", alpha=0.6)\n",
    "plt.plot(df.index[train_size:], y_pred_actual, label=\"Predicted Mean\", color=\"blue\")\n",
    "plt.fill_between(df.index[train_size:], \n",
    "                 y_pred_actual - 2 * y_pred_std_actual, \n",
    "                 y_pred_actual + 2 * y_pred_std_actual, \n",
    "                 color=\"blue\", alpha=0.3, label=\"Uncertainty (95%)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Electricity Production\")\n",
    "plt.legend()\n",
    "plt.title(\"Bayesian Neural Network Time Series Forecasting with Uncertainty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data = df.iloc[-12:].values \n",
    "\n",
    "last_data_scaled = scaler.transform(last_data.reshape(1, -1))[:, 1:]\n",
    "\n",
    "future_pred_samples = np.array([best_model(last_data_scaled) for _ in range(100)])\n",
    "\n",
    "future_pred_mean = future_pred_samples.mean()\n",
    "future_pred_std = future_pred_samples.std()\n",
    "\n",
    "future_pred_actual = scaler.inverse_transform([[future_pred_mean] + list(last_data_scaled[0])])[0, 0]\n",
    "future_pred_std_actual = scaler.inverse_transform([[future_pred_std] + list(last_data_scaled[0])])[0, 0]\n",
    "\n",
    "print(f\"ðŸ”¹ Prediksi Produksi Listrik Periode Berikutnya: {future_pred_actual:.2f}\")\n",
    "print(f\"ðŸ”¹ Estimasi Ketidakpastian (Â±2Ïƒ): Â±{2 * future_pred_std_actual:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
