{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from transformers import ViTFeatureExtractor, TFViTForImageClassification\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import (accuracy_score, roc_curve, auc, precision_recall_curve, \n",
    "                             confusion_matrix, roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay, \n",
    "                             classification_report, recall_score, balanced_accuracy_score, f1_score, precision_score)\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.preprocessing import label_binarize \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"D:\\Download\\archive\\seg_train\\seg_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"D:\\Download\\archive\\seg_test\\seg_test\\buildings\\20061.jpg\")\n",
    "print(np.min(img), np.max(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/vit-base-patch16-224-in21k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = TFViTForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = best_model.predict(val_generator)\n",
    "y_test = val_generator.classes\n",
    "y_pred = np.argmax(y_predict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.matshow(matrix)\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(matrix, square  =True, annot = True, cbar = False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_ovr = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "print(roc_auc_ovr)\n",
    "classes = np.unique(y_test)\n",
    "\n",
    "y_test_bin = label_binarize(y_test, classes = classes)\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_test_bin[:,i],\n",
    "        y_pred[:,i],\n",
    "        name=f\"Class {i} vs Rest\",\n",
    "        plot_chance_level =(i==0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = dict()\n",
    "recall = dict()\n",
    "pr_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test_bin[:,i], y_pred[:,i])\n",
    "    pr_auc[i] = auc(recall[i], precision[i])\n",
    "    PrecisionRecallDisplay.from_predictions(\n",
    "        y_test_bin[:,i],\n",
    "        y_pred[:,i],\n",
    "        name=f\"Class {i} vs Rest\",\n",
    "        plot_chance_level =(i==0)\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Evaluation:\")\n",
    "results = best_model.evaluate(val_generator, y_test, verbose=0)\n",
    "metrics = dict(zip(best_model.metrics_names, results))\n",
    "for name, value in metrics.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = best_model.predict(train_generator)\n",
    "y_test_pred = best_model.predict(val_generator)\n",
    "\n",
    "if y_train.ndim > 1 and y_train.shape[1] > 1:\n",
    "    y_train_true = np.argmax(y_train, axis=1)\n",
    "    y_test_true = np.argmax(y_test, axis=1)\n",
    "    y_train_pred = np.max(y_train_pred, axis=1)  \n",
    "    y_test_pred = np.max(y_test_pred, axis=1)\n",
    "else:\n",
    "    y_train_true = y_train.ravel() \n",
    "    y_test_true = y_test.ravel()\n",
    "\n",
    "train_auc = roc_auc_score(y_train_true, y_train_pred, multi_class='ovr')\n",
    "test_auc = roc_auc_score(y_test_true, y_test_pred, multi_class='ovr')\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss'] \n",
    "train_acc = history.history['accuracy']\n",
    "test_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc, label='Train Accuracy', linestyle='dashed')\n",
    "plt.plot(test_acc, label='Test Accuracy', linestyle='dashed')\n",
    "plt.axhline(train_auc, color='blue', linestyle='solid', label=f'Train AUC: {train_auc:.3f}')\n",
    "plt.axhline(test_auc, color='red', linestyle='solid', label=f'Test AUC: {test_auc:.3f}')\n",
    "plt.title('Training & Test Accuracy with AUC')\n",
    "plt.ylabel('Accuracy / AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(test_loss, label='Test Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAdvanced Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAdvanced Metrics:\")\n",
    "print(f\"- Maximum Training Accuracy: {max(train_acc):.4f}\")\n",
    "print(f\"- Minimum Test Loss: {min(test_loss):.4f}\")\n",
    "print(f\"- Optimal Epochs: {len(train_loss)}\")\n",
    "print(f\"- Maximum Training AUC: {train_auc:.4f}\")\n",
    "print(f\"- Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_model, train_generator)\n",
    "\n",
    "if hasattr(val_generator, 'numpy'):\n",
    "    val_generator = val_generator.numpy()\n",
    "shap_values = explainer(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values.values, val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, class_indices, img_size=(224, 224)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, img_size) / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    class_label = list(class_indices.keys())[predicted_class] \n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Predicted: {class_label}\")\n",
    "    plt.show()\n",
    "\n",
    "predict_image(vit, \"path_to_new_image.jpg\", train_generator.class_indices)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
