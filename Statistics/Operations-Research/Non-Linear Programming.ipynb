{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Karush-Kuhn-Tucker (KKT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisikan variabel\n",
    "x1, x2, lambd = sp.symbols('x1 x2 lambd')\n",
    "\n",
    "# Fungsi Lagrange\n",
    "L = x1*2 + x2*2 + 3*x1 + 4*x2 + lambd * (x1 + 2*x2 - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turunan pertama (KKT conditions)\n",
    "eq1 = sp.diff(L, x1)  # dL/dx1 = 0\n",
    "eq2 = sp.diff(L, x2)  # dL/dx2 = 0\n",
    "eq3 = sp.diff(L, lambd)  # dL/dlambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cari solusi sistem persamaan\n",
    "solution = sp.solve((eq1, eq2, eq3), (x1, x2, lambd))\n",
    "x1_opt, x2_opt, lambd_opt = solution[x1], solution[x2], solution[lambd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung nilai minimum\n",
    "f_min = x1_opt*2 + x2_opt*2 + 3*x1_opt + 4*x2_opt\n",
    "\n",
    "print(f\"Solusi optimal KKT: x1 = {x1_opt}, x2 = {x2_opt}\")\n",
    "print(f\"Nilai minimum f(x): {f_min}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Newton-Raphson untuk Sistem Persamaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi turunan pertama (gradien)\n",
    "def grad(x):\n",
    "    x1, x2, lambd = x\n",
    "    return np.array([\n",
    "        2*x1 + 3 + lambd,  # dL/dx1 = 0\n",
    "        2*x2 + 4 + 2*lambd,  # dL/dx2 = 0\n",
    "        x1 + 2*x2 - 6  # dL/dlambda = 0\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriks turunan kedua (Hessian + Kendala)\n",
    "def hessian(x):\n",
    "    return np.array([\n",
    "        [2, 0, 1],  # d²L/dx1², d²L/dx1dx2, d²L/dx1dλ\n",
    "        [0, 2, 2],  # d²L/dx2dx1, d²L/dx2², d²L/dx2dλ\n",
    "        [1, 2, 0]   # d²L/dλdx1, d²L/dλdx2, d²L/dλ²\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nilai awal\n",
    "x_init = np.array([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterasi Newton-Raphson\n",
    "tolerance = 1e-6\n",
    "max_iter = 100\n",
    "\n",
    "for i in range(max_iter):\n",
    "    grad_val = grad(x_init)\n",
    "    hess_val = hessian(x_init)\n",
    "    delta_x = np.linalg.solve(hess_val, -grad_val)\n",
    "    x_init = x_init + delta_x\n",
    "    if np.linalg.norm(delta_x) < tolerance:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_opt, x2_opt, lambd_opt = x_init\n",
    "\n",
    "print(f\"Solusi optimal Newton-Raphson: x1 = {x1_opt}, x2 = {x2_opt}\")\n",
    "print(f\"Nilai minimum f(x): {x1_opt*2 + x2_opt*2 + 3*x1_opt + 4*x2_opt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Gradient Descent dengan Kendala Equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1  # Learning rate\n",
    "x1, x2 = 2, 2  # Nilai awal\n",
    "tolerance = 1e-6\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(max_iter):\n",
    "    # Gradien dari f(x)\n",
    "    grad_x1 = 2*x1 + 3\n",
    "    grad_x2 = 2*x2 + 4\n",
    "\n",
    "    # Update dengan gradient descent\n",
    "    x1 -= alpha * grad_x1\n",
    "    x2 -= alpha * grad_x2\n",
    "\n",
    "    # Proyeksi ke kendala: x1 + 2x2 = 6\n",
    "    x2 = (6 - x1) / 2\n",
    "\n",
    "    # Cek konvergensi\n",
    "    if abs(grad_x1) < tolerance and abs(grad_x2) < tolerance:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Solusi optimal Gradient Descent: x1 = {x1}, x2 = {x2}\")\n",
    "print(f\"Nilai minimum f(x): {x1*2 + x2*2 + 3*x1 + 4*x2}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
